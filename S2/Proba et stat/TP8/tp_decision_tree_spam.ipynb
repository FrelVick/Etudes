{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de ce TP, nous allons explorer la notion d'information mutuelle dans le cadre d'une tâche de classification de mails :  un mail est-il un spam ou un ham . \n",
    "\n",
    "\n",
    "\n",
    "# Les données\n",
    "\n",
    "Récupérer les données (lingspam.tgz) et décompresser l'archive. \n",
    "- regarder le contenu de l'archive\n",
    "- il existe différentes versions des données, lesquelles ? \n",
    "\n",
    "Voici du code pour lire et mettre en forme les donnéés (avec les imports aussi): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle, os \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = pickle.load(open(\"lingspam.p\", \"rb\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- De quels types sont les variables  train_texts, test_texts, train_labels, test_labels ? \n",
    "- leurs dimensions ? \n",
    "- De quels types sont les données stockées ? \n",
    "- Combien y-a-t-il d'exemple pour l'apprentissage et le test  ?\n",
    "\n",
    "## Matrice terme/document \n",
    "\n",
    "Nous allons maintenant transformer les données en utilisant sklearn. Pour cela il existe un outil: CountVectorizer\n",
    "Cet objet permet de générer une matrice de compte. Nous allons utiliser la version binaire: chaque caractéristique est binaire, indépendante des autres caractéristique et représente la présence (ou l'absence) d'un mot dans un mail.  Pour cela nous procédons en 2 étapes: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "x_train = cv.fit_transform(train_texts) # étape 1 \n",
    "x_test = cv.transform(test_texts) # étape 2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarder la documentation de sklearn sur CountVectorizer et répondre aux questions suivantes\n",
    "\n",
    "## Questions sur les données\n",
    "\n",
    "- Comment expliquer ces deux étapes ? \n",
    "- Combien y-a-t-il de document dans les données de train ? \n",
    "- Combien y-a-t-il de document dans les données de test ? \n",
    "- Quel est le vocabulaire ? \n",
    "- Afficher le vecteur associé au premier document d'apprentissage? \n",
    "- Quel est le type de l'objet x_train ? Expliquer ce choix ? \n",
    "- Comment trouver le lien entre un mot et son indice ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cela permet de transformer les textes en matrice qui compte le nombre d'occurence de chaque token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb d element de train : (2604, 57752)\n",
      "nb d element de test : (290, 57752)\n"
     ]
    }
   ],
   "source": [
    "print 'nb d element de train :', x_train.shape\n",
    "print 'nb d element de test :', x_test.shape\n",
    "voc = cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 50070)\t1\n",
      "  (0, 41883)\t1\n",
      "  (0, 20948)\t1\n",
      "  (0, 16243)\t1\n",
      "  (0, 16311)\t1\n",
      "  (0, 1432)\t1\n",
      "  (0, 11805)\t1\n",
      "  (0, 22223)\t1\n",
      "  (0, 39743)\t1\n",
      "  (0, 41876)\t1\n",
      "  (0, 28323)\t1\n",
      "  (0, 14438)\t1\n",
      "  (0, 38781)\t1\n",
      "  (0, 7202)\t1\n",
      "  (0, 37211)\t1\n",
      "  (0, 29754)\t1\n",
      "  (0, 757)\t1\n",
      "  (0, 1011)\t1\n",
      "  (0, 1435)\t1\n",
      "  (0, 51425)\t1\n",
      "  (0, 8916)\t1\n",
      "  (0, 54082)\t1\n",
      "  (0, 25492)\t1\n",
      "  (0, 38579)\t1\n",
      "  (0, 29324)\t1\n",
      "  :\t:\n",
      "  (0, 22160)\t1\n",
      "  (0, 28107)\t1\n",
      "  (0, 5432)\t1\n",
      "  (0, 26395)\t1\n",
      "  (0, 42751)\t1\n",
      "  (0, 6201)\t1\n",
      "  (0, 8420)\t1\n",
      "  (0, 13637)\t1\n",
      "  (0, 49150)\t1\n",
      "  (0, 39291)\t1\n",
      "  (0, 17196)\t1\n",
      "  (0, 14333)\t1\n",
      "  (0, 22929)\t1\n",
      "  (0, 14730)\t1\n",
      "  (0, 18861)\t1\n",
      "  (0, 56129)\t1\n",
      "  (0, 53944)\t1\n",
      "  (0, 36493)\t1\n",
      "  (0, 16233)\t1\n",
      "  (0, 22337)\t1\n",
      "  (0, 11900)\t1\n",
      "  (0, 6830)\t1\n",
      "  (0, 44930)\t1\n",
      "  (0, 5073)\t1\n",
      "  (0, 3916)\t1\n"
     ]
    }
   ],
   "source": [
    "print type(x_train)\n",
    "print x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbre de décision\n",
    "\n",
    "La classe pour apprendre un arbre de décision est DecisionTreeClassifier. Regarder la documentation de cette classe et commenter la ligne suivante: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(criterion=\"entropy\", splitter='best', random_state = 0, max_depth=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apprendre l'arbre de décision sur les données d'apprentissage\n",
    "- comment connaitre la prédiction du modèle pour le premier document de test ? \n",
    "- la réponse du modèle est-elle correcte ? \n",
    "- Calculer le score de bonne prédiction sur les données de test. \n",
    "- Afficher les 10  caractéristiques sélectionnnés comme les plus importantes lors de la contruction de l'arbre de décision. \n",
    "- Regarder l'importance pour toutes les caractéristiques, que constatez-vous ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95862068965517244"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def top_k(k, imp):\n",
    "    res = sorted(zip(range(len(imp)), imp), reverse=True, key=operator.itemgetter(1))\n",
    "    return res[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "0.263709204449 language\n",
      "0.177927297975 free\n",
      "0.0777815507395 you\n",
      "0.070937972508 university\n",
      "0.0507699259446 linguistics\n",
      "0.0292523492465 edu\n",
      "0.0276051786827 english\n",
      "0.0243224999614 your\n",
      "0.0232897516966 remove\n",
      "0.0208283972812 click\n",
      "0.017417435449 research\n",
      "0.0150030248667 syntax\n",
      "0.0149088710052 share\n",
      "0.0114560297806 http\n",
      "0.0108131485559 de\n",
      "0.00844281436105 pp\n",
      "0.00750800744329 anyone\n",
      "0.0074266466415 visit\n",
      "0.00737689518175 fax\n",
      "0.00712912615655 call\n",
      "0.00697347556023 restoring\n",
      "0.00690538745143 suggestions\n",
      "0.00678823908332 interviews\n",
      "0.00670094398132 ftp\n",
      "0.00634679827869 via\n",
      "0.00623496912229 gino\n",
      "0.00619815334066 nl\n",
      "0.00613300126313 role\n",
      "0.00609663391423 exclusive\n",
      "0.00591081751306 official\n",
      "0.00528860354546 ll\n",
      "0.00522811988669 price\n",
      "0.0050500942987 equitybuilder\n",
      "0.00460385995232 xxx\n",
      "0.00452962389203 or\n",
      "0.00450870404082 seems\n",
      "0.00395774541051 springfield\n",
      "0.00355940579297 how\n",
      "0.00352743241026 sending\n",
      "0.00344082061807 chosen\n",
      "0.00326858751139 information\n",
      "0.00231369357318 following\n",
      "0.00214136253588 as\n",
      "0.00192511203727 about\n",
      "0.00192511203727 mailing\n",
      "0.0016342937557 authors\n",
      "0.0016342937557 but\n",
      "0.0016342937557 pubcdrom\n",
      "0.0016342937557 some\n",
      "0.0 00\n"
     ]
    }
   ],
   "source": [
    "tk= top_k(50, classifier.feature_importances_)\n",
    "print (classifier.feature_importances_!=0).sum()\n",
    "for cp in tk:\n",
    "    print cp[1], cv.get_feature_names()[cp[0]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profondeur de l'arbre \n",
    "\n",
    "Effectuer un apprentissage, puis évaluer le modèle avec différentes profondeurs maximum d'arbre (1,2,5,10,15,20,100,None): \n",
    "- construire le classifieur\n",
    "- calculer son score sur le test\n",
    "Une profondeur maximum de *None*  signifie qu'il n'y a pas de limitation. \n",
    "- Que constatez vous ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion=\"entropy\", splitter='best', random_state=0, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95862068965517244"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* depth = 1 : 0.82758620689655171\n",
    "* depth = 2 : 0.91724137931034477\n",
    "* depth = 5 : 0.93103448275862066\n",
    "* depth = 10 : 0.96206896551724141\n",
    "* depth = 15 : 0.95862068965517244\n",
    "* depth = 20 : 0.95862068965517244\n",
    "* depth = 100 : 0.95862068965517244\n",
    "* depth = None : 0.95862068965517244\n",
    "\n",
    "On constate que le résultat ne s'améliore plus même qu'il réduit avant de stagner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de l'arbre\n",
    "Il est possible de générer une figure qui représente l'arbre ainsi: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import  export_graphviz\n",
    "export_graphviz(clf, out_file = \"unNomDeFichier\", feature_names = cv.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis vous pouvez convertir le fichier en pdf grâce à la commande unix suivante : \n",
    " dot -Tpdf unNomDeFichier  -o maFigure.pdf\n",
    "\n",
    "- Visualiser l'arbre \n",
    "- Regarder les seuils de décision  appliqués ? Expliquer les valeurs obtenues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information mutuelle \n",
    "\n",
    "A partir des données d'apprentissage, calculer: \n",
    "- l'entropie de la variable Y (qui représente la classe)\n",
    "- l'information mutuelle entre Y et chaque caractéristique binaire\n",
    "- quels sont les 10 caractéristiques (mots) ayant l'information mutuelle la plus élevée. \n",
    "\n",
    "Remarque: Pour accéder facilement aux comptes, il suffit d'apprendre un Bayésien Naif de type Bernoulli avec sklearn. L'objet résultant contient les comptes. Recouper ces résultats avec ceux obtenus avec l'arbre de décision. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
